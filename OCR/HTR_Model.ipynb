{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BvKQMYoGem-H"
      ],
      "authorship_tag": "ABX9TyOH1Jeq+/5LBGFrUtf1pqKi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahirshson02/deeplearning-ocr-rnn/blob/main/OCR/HTR_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RESEARCH**\n",
        "\n",
        "# The code cell below is the implementation for basic OCR. Not likely to be able to be utilized for handwritten text recognition."
      ],
      "metadata": {
        "id": "rVGs_xSreR09"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34bb2a49",
        "outputId": "120366a1-3b0e-43c8-a837-937497ae0942"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense\n",
        "from keras.optimizers import Adam\n",
        "import os\n",
        "import cv2\n",
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Assuming the dataset is already downloaded\n",
        "\n",
        "# Set the path to the directory containing all images\n",
        "# Path points directly to a folder with images\n",
        "image_folder_path = './english-handwritten-characters-dataset/Img'\n",
        "\n",
        "# Load the english.csv file to potentially map filenames to characters\n",
        "csv_path = './english-handwritten-characters-dataset/english.csv'\n",
        "try:\n",
        "    label_df = pd.read_csv(csv_path)\n",
        "    # Assuming the CSV has columns like 'image' and 'label' based on variable inspection\n",
        "    label_mapping = dict(zip(label_df['image'], label_df['label']))\n",
        "    print(\"Loaded label mapping from english.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Warning: {csv_path} not found. Labels will be extracted from filenames if possible.\")\n",
        "    label_mapping = {}\n",
        "\n",
        "\n",
        "print(f\"Loading images from a single folder: {image_folder_path}\")\n",
        "\n",
        "# Iterate through the files in the single image folder\n",
        "try:\n",
        "    for image_name in os.listdir(image_folder_path):\n",
        "        image_path = os.path.join(image_folder_path, image_name)\n",
        "        # Check if it's a file\n",
        "        if os.path.isfile(image_path):\n",
        "            img = cv2.imread(image_path)\n",
        "            if img is not None: # Add a check to ensure the image was loaded successfully\n",
        "                img = cv2.resize(img, (64,64))\n",
        "                img = np.array(img, dtype=np.float32)\n",
        "                img = img/255\n",
        "                images.append(img)\n",
        "\n",
        "                # Attempt to get label from filename or mapping\n",
        "                # The filename format is like 'Img/imgNNN-NNN.png'\n",
        "                # We need to match this format to the 'image' column in the CSV\n",
        "                csv_image_name = f'Img/{image_name}'\n",
        "                if csv_image_name in label_mapping:\n",
        "                    labels.append(label_mapping[csv_image_name])\n",
        "                else:\n",
        "                     # Attempt to extract the part after the hyphen and before the extension as a fallback\n",
        "                    try:\n",
        "                        label_code = image_name.split('-')[1].split('.')[0]\n",
        "                        labels.append(label_code)\n",
        "                        print(f\"Warning: Image {csv_image_name} not found in CSV, using label from filename: {label_code}\")\n",
        "                    except IndexError:\n",
        "                        print(f\"Warning: Could not extract label from filename: {image_name} and not found in CSV.\")\n",
        "                        labels.append(\"unknown\") # Assign a default label if extraction fails\n",
        "\n",
        "\n",
        "            else:\n",
        "                print(f\"Warning: Could not load image {image_path}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Image folder not found: {image_folder_path}\")\n",
        "\n",
        "\n",
        "print(f\"Number of images loaded: {len(images)}\")\n",
        "print(f\"Number of labels loaded: {len(labels)}\")\n",
        "\n",
        "if len(images) == 0:\n",
        "    print(\"Error: No images were loaded. Please check the path to the single image folder.\")\n",
        "else:\n",
        "    X = np.array(images)\n",
        "    y = np.array(labels)\n",
        "\n",
        "    # Continue with preprocessing and model training as before\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y)\n",
        "    from sklearn.utils import shuffle\n",
        "    X_sh, y_sh = shuffle(X, y, random_state=42)\n",
        "\n",
        "    # Assuming the model architecture and compilation are the same\n",
        "    # You might need to adjust the output layer if the number of classes is different\n",
        "    num_classes = len(le.classes_)\n",
        "    print(f\"Number of classes identified: {num_classes}\")\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(64,64,3)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3,3),  activation='relu'))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3,3),  activation='relu'))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=128, activation='relu'))\n",
        "    model.add(Dense(units=64, activation='relu'))\n",
        "    model.add(Dense(units=32, activation='relu'))\n",
        "    model.add(Dense(units=num_classes, activation='softmax')) # Use num_classes here\n",
        "\n",
        "\n",
        "    adam_optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "    model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    print(\"Model compilation complete. Ready for training if data is loaded.\")\n",
        "\n",
        "\n",
        "    history = model.fit(X_sh, y_sh ,validation_split=0.2, epochs=20, batch_size=32)\n",
        "\n",
        "    model.evaluate(\n",
        "        X_sh,\n",
        "        y_sh,\n",
        "        batch_size=32,\n",
        "        verbose=auto,\n",
        "        sample_weight=None,\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: ./english-handwritten-characters-dataset/english.csv not found. Labels will be extracted from filenames if possible.\n",
            "Loading images from a single folder: ./english-handwritten-characters-dataset/Img\n",
            "Error: Image folder not found: ./english-handwritten-characters-dataset/Img\n",
            "Number of images loaded: 0\n",
            "Number of labels loaded: 0\n",
            "Error: No images were loaded. Please check the path to the single image folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "od.download('https://www.kaggle.com/datasets/dhruvildave/english-handwritten-characters-dataset')\n",
        "# requires kaggle username and API key, can be obtained from kaggle account settings as a json file."
      ],
      "metadata": {
        "id": "cyosYymvbfTT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "306537cf-22f4-4d27-c0e9-b4449d1c0404"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'od' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-4184878447.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.kaggle.com/datasets/dhruvildave/english-handwritten-characters-dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# requires kaggle username and API key, can be obtained from kaggle account settings as a json file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'od' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# New dataset for handwritten text below.\n",
        "\n"
      ],
      "metadata": {
        "id": "BvKQMYoGem-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "od.download('https://www.kaggle.com/datasets/nibinv23/iam-handwriting-word-database')\n",
        "# requires kaggle username and API key, can be obtained from kaggle account settings as a json file."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdEkjZ1cZer-",
        "outputId": "1aa0d16a-5312-4fb6-e4f0-dd3c4ab369f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: alexandermulet\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/nibinv23/iam-handwriting-word-database\n",
            "Downloading iam-handwriting-word-database.zip to ./iam-handwriting-word-database\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.10G/1.10G [00:10<00:00, 115MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This code is the preliminary implementation for handwritten character recognition, built upon concepts learned from the OCR model research.\n",
        "\n",
        "Known as HTR (Handwritten Text Recognition), this model looks to combine layers from both CNN and RNN to accurately parse and sequence data into setences. The CNN acts as a feature extractor and the RNN will be used for sequence processing."
      ],
      "metadata": {
        "id": "uRZefB0OfGQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA LOADING & PREPROCESSING (HTR)\n"
      ],
      "metadata": {
        "id": "mcHchMWJiTZb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb040102",
        "outputId": "53badfc8-6b45-40c9-d7a3-3093dd244463",
        "collapsed": true
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "# Path to the downloaded dataset\n",
        "dataset_path = './iam-handwriting-word-database'\n",
        "words_transcription_file = os.path.join(dataset_path, 'words_new.txt')\n",
        "words_images_base_path = os.path.join(dataset_path, 'iam_words')\n",
        "\n",
        "# Load transcriptions\n",
        "transcriptions = {}\n",
        "with open(words_transcription_file, 'r') as f:\n",
        "    for line in f:\n",
        "        if line.strip() and not line.strip().startswith('#'): # Skip empty lines and comments\n",
        "            parts = line.strip().split(' ', 1) # Split only on the first space\n",
        "            if len(parts) == 2:\n",
        "                image_id, transcription = parts\n",
        "                # Clean the transcription if necessary (e.g., remove unwanted characters)\n",
        "                transcriptions[image_id] = transcription.replace('|', ' ') # Example cleaning\n",
        "\n",
        "print(f\"Loaded {len(transcriptions)} transcriptions.\")\n",
        "\n",
        "# Prepare lists for image paths and labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "print(\"Gathering image paths and labels...\")\n",
        "# Add a counter to print only a few examples\n",
        "count = 0\n",
        "max_examples = 10\n",
        "\n",
        "for image_id, transcription in transcriptions.items():\n",
        "    # Construct the full path based on image_id format and the provided sample path\n",
        "    # Example image_id from words_new.txt: a01-000u-00-00\n",
        "    # Confirmed actual path structure: iam_words/words/writer_id/writer_id-page_num/image_id.png\n",
        "    # e.g., iam_words/words/a01/a01-000u/a01-000u-00-00.png\n",
        "    parts = image_id.split('-')\n",
        "    if len(parts) >= 4: # Ensure enough parts for the expected structure\n",
        "        writer_id = parts[0] # Full writer ID (e.g., a01)\n",
        "        writer_page_num = parts[0] + '-' + parts[1] # Writer ID and page number (e.g., a01-000u)\n",
        "        image_filename = f\"{image_id}.png\" # Full image filename\n",
        "\n",
        "        relative_path_corrected = os.path.join(\n",
        "            'words', # Include the 'words' subdirectory\n",
        "            writer_id,\n",
        "            writer_page_num,\n",
        "            image_filename\n",
        "        )\n",
        "\n",
        "        full_image_path = os.path.join(words_images_base_path, relative_path_corrected)\n",
        "\n",
        "\n",
        "        # Add print statements for debugging paths\n",
        "        if count < max_examples:\n",
        "            print(f\"Checking path for image ID {image_id}: {full_image_path}\")\n",
        "            print(f\"Does path exist? {os.path.exists(full_image_path)}\")\n",
        "            count += 1\n",
        "\n",
        "        # Stop printing after max_examples to avoid excessive output\n",
        "        #if count == max_examples:\n",
        "          #print(\"...\")\n",
        "\n",
        "\n",
        "        if os.path.exists(full_image_path):\n",
        "            image_paths.append(full_image_path)\n",
        "            labels.append(transcription)\n",
        "        # else:\n",
        "            # Uncomment for debugging missing files:\n",
        "            # if count < max_examples + 5: # Print a few more missing paths\n",
        "            #    print(f\"Path not found for image ID {image_id}: {full_image_path}\")\n",
        "\n",
        "\n",
        "print(f\"Found {len(image_paths)} images with corresponding transcriptions.\")\n",
        "\n",
        "# Create a character vocabulary and mapping\n",
        "all_chars = sorted(list(set(''.join(labels))))\n",
        "char_to_num = tf.keras.layers.StringLookup(\n",
        "    vocabulary=all_chars, mask_token=None, oov_token=\"[UNK]\"\n",
        ")\n",
        "num_to_char = tf.keras.layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, oov_token=\"[UNK]\", invert=True\n",
        ")\n",
        "print(f\"Vocabulary size: {len(all_chars)}\")\n",
        "print(f\"Vocabulary: {all_chars}\")\n",
        "\n",
        "# Preprocessing function for images and labels\n",
        "def process_data(image_path, label):\n",
        "    # Ensure image_path is a string tensor\n",
        "    image_path = tf.cast(image_path, tf.string) # Explicitly cast to string\n",
        "\n",
        "    # Image preprocessing\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.io.decode_png(img, channels=1) # Decode as grayscale\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32) # Normalize to [0, 1]\n",
        "\n",
        "    # Resize image (maintain aspect ratio and pad)\n",
        "    img_height = 64 # Keep consistent height\n",
        "    img_width = 256 # Choose a suitable fixed width\n",
        "    height, width = tf.shape(img)[0], tf.shape(img)[1]\n",
        "    scale = tf.cast(img_height, tf.float32) / tf.cast(height, tf.float32) # Cast both to float32 before division\n",
        "    img_width_new = tf.cast(tf.cast(width, tf.float32) * scale, tf.int32)\n",
        "    img = tf.image.resize(img, [img_height, img_width_new])\n",
        "    img = tf.image.pad_to_bounding_box(img, 0, 0, img_height, img_width)\n",
        "\n",
        "\n",
        "    # Label preprocessing (convert text to numerical sequence)\n",
        "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
        "\n",
        "    return img, label\n",
        "\n",
        "# Create TensorFlow Datasets\n",
        "# Split data into training and validation sets\n",
        "train_image_paths, val_image_paths, train_labels, val_labels = train_test_split(\n",
        "    image_paths, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_image_paths, train_labels))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_image_paths, val_labels))\n",
        "\n",
        "# Apply preprocessing and batching\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.map(process_data, num_parallel_calls=AUTOTUNE).batch(32).cache().prefetch(AUTOTUNE)\n",
        "val_ds = val_ds.map(process_data, num_parallel_calls=AUTOTUNE).batch(32).cache().prefetch(AUTOTUNE)\n",
        "\n",
        "print(\"\\nData preprocessing complete. Created TensorFlow Datasets.\")\n",
        "print(f\"Training dataset size: {tf.data.experimental.cardinality(train_ds).numpy()} batches\")\n",
        "print(f\"Validation dataset size: {tf.data.experimental.cardinality(val_ds).numpy()} batches\")\n",
        "\n",
        "# Now you can use train_ds and val_ds for training your HTR model"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 44564 transcriptions.\n",
            "Gathering image paths and labels...\n",
            "Checking path for image ID a01-000u-00-00: ./iam-handwriting-word-database/iam_words/words/a01/a01-000u/a01-000u-00-00.png\n",
            "Does path exist? True\n",
            "Checking path for image ID a01-000u-00-01: ./iam-handwriting-word-database/iam_words/words/a01/a01-000u/a01-000u-00-01.png\n",
            "Does path exist? True\n",
            "Checking path for image ID a01-000u-00-02: ./iam-handwriting-word-database/iam_words/words/a01/a01-000u/a01-000u-00-02.png\n",
            "Does path exist? True\n",
            "Checking path for image ID a01-000u-00-03: ./iam-handwriting-word-database/iam_words/words/a01/a01-000u/a01-000u-00-03.png\n",
            "Does path exist? True\n",
            "Checking path for image ID a01-000u-00-04: ./iam-handwriting-word-database/iam_words/words/a01/a01-000u/a01-000u-00-04.png\n",
            "Does path exist? True\n",
            "Checking path for image ID a01-000u-00-05: ./iam-handwriting-word-database/iam_words/words/a01/a01-000u/a01-000u-00-05.png\n",
            "Does path exist? True\n",
            "Checking path for image ID a01-000u-00-06: ./iam-handwriting-word-database/iam_words/words/a01/a01-000u/a01-000u-00-06.png\n",
            "Does path exist? True\n",
            "Checking path for image ID a01-000u-01-00: ./iam-handwriting-word-database/iam_words/words/a01/a01-000u/a01-000u-01-00.png\n",
            "Does path exist? True\n",
            "Checking path for image ID a01-000u-01-01: ./iam-handwriting-word-database/iam_words/words/a01/a01-000u/a01-000u-01-01.png\n",
            "Does path exist? True\n",
            "Checking path for image ID a01-000u-01-02: ./iam-handwriting-word-database/iam_words/words/a01/a01-000u/a01-000u-01-02.png\n",
            "Does path exist? True\n",
            "Found 44564 images with corresponding transcriptions.\n",
            "Vocabulary size: 79\n",
            "Vocabulary: [' ', '!', '\"', '#', '$', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "\n",
            "Data preprocessing complete. Created TensorFlow Datasets.\n",
            "Training dataset size: 1115 batches\n",
            "Validation dataset size: 279 batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEXT STEPS\n",
        "\n",
        "\n",
        "\n",
        "*   Define model structure using elements from CNN and RNN\n",
        "*   Training and validation\n",
        "*   Test with a sample dataset\n",
        "*   Polish and documentation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tKyHfOXvgo7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL TEMPLATE"
      ],
      "metadata": {
        "id": "pNs_9_BsiMDF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "612a0110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "578dd3e9-b897-48a6-f580-d66ea7712bb2"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Reshape, Dense, GRU, Bidirectional, Input, Activation, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Assuming img_height, img_width, and vocabulary size (num_classes) from preprocessing are available\n",
        "img_height = 64\n",
        "img_width = 256 # Example width\n",
        "num_classes = len(all_chars) + 1 # +1 for CTC blank label\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (img_height, img_width, 1) # Images are grayscale\n",
        "\n",
        "# --- CNN Feature Extraction Part (Simplified) ---\n",
        "input_img = Input(shape=input_shape, name='image_input')\n",
        "\n",
        "# Simplified Convolutional layers\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img) # Fewer filters\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x) # Fewer filters\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# You can add one more layer if needed, but keeping it minimal for now\n",
        "# x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "# x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "\n",
        "# Reshape the output for the RNN layers\n",
        "# The target shape is (batch_size, sequence_length, feature_dimension)\n",
        "# The sequence length will be the width of the last pooling layer's output\n",
        "# The feature dimension will be height * number of filters in the last conv layer\n",
        "\n",
        "\n",
        "# Calculate the shape after CNN layers (assuming fixed input width and 2 MaxPooling layers)\n",
        "cnn_output_height = img_height // (2*2)\n",
        "cnn_output_width = img_width // (2*2)\n",
        "cnn_output_filters = 32 # Number of filters in the last Conv2D layer\n",
        "\n",
        "# Calculate the feature dimension per sequence step\n",
        "feature_dimension = cnn_output_height * cnn_output_filters\n",
        "\n",
        "# Reshape for RNN (batch_size, sequence_length, feature_dimension)\n",
        "# The sequence length is the width of the CNN output\n",
        "x = Reshape(target_shape=(cnn_output_width, feature_dimension), name='reshape')(x)\n",
        "\n",
        "# --- RNN Sequence Processing Part (Simplified using one Bidirectional GRU) ---\n",
        "\n",
        "gru_units = 64 # Fewer units\n",
        "x = Bidirectional(GRU(gru_units, return_sequences=True, kernel_initializer='he_normal'), name='gru1')(x)\n",
        "x = Bidirectional(GRU(gru_units, return_sequences=False, kernel_initializer='he_normal'), name='gru2')(x)\n",
        "\n",
        "\n",
        "# --- Output Layer for CTC ---\n",
        "\n",
        "# The output layer predicts the probability distribution over characters for each step in the sequence\n",
        "# num_classes is the size of your vocabulary + 1 for the blank label used by CTC\n",
        "output = Dense(num_classes, activation='softmax', name='dense_output')(x)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=input_img, outputs=output)\n",
        "\n",
        "# --- CTC Loss Function ---\n",
        "# CTC loss requires the model's output, the true labels, the input sequence length, and the label sequence length\n",
        "\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, y_true, input_length, label_length = args\n",
        "    # The CTC loss function is more stable with softmax activation\n",
        "    # y_pred = y_pred[:, :, :] # Slice to remove the last dimension if it's 1 (not needed with softmax)\n",
        "    return K.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "\n",
        "# Define inputs for the CTC loss\n",
        "labels = Input(name='the_labels', shape=[None], dtype='float32') # True labels as sequences\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')   # Length of the input sequence (width of CNN output)\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')   # Length of the true label sequence\n",
        "\n",
        "# Define the training model (includes all inputs needed for CTC loss calculation)\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([output, labels, input_length, label_length])\n",
        "training_model = Model(inputs=[input_img, labels, input_length, label_length], outputs=loss_out)\n",
        "\n",
        "# Compile the training model\n",
        "adam_optimizer = Adam(learning_rate=0.001) # You can adjust the learning rate\n",
        "training_model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=adam_optimizer)\n",
        "\n",
        "# Note: The 'model' is used for prediction after training\n",
        "# The 'training_model' is used for training with the CTC loss\n",
        "\n",
        "# You will need to create a custom data generator to feed data to the training_model\n",
        "# The generator should yield batches of ([image_input, the_labels, input_length, label_length], dummy_output_for_loss)\n",
        "# where dummy_output_for_loss can be zeros or None since the loss is calculated within the model\n",
        "\n",
        "model = Model(inputs=[input_img, labels, input_length, label_length], outputs=loss_out)\n",
        "model.compile(optimizer='adam')\n",
        "\n",
        "model.fit()\n",
        "\n",
        "#print(\"Simplified HTR Model Template Defined (using minimal CNN and one Bidirectional GRU layer).\")\n",
        "#training_model.summary()\n",
        "#model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simplified HTR Model Template Defined (using minimal CNN and one Bidirectional GRU layer).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m,   │        \u001b[38;5;34m160\u001b[0m │ image_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m,   │      \u001b[38;5;34m4,640\u001b[0m │ max_pooling2d_8[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_9[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m221,952\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m74,496\u001b[0m │ gru1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m10,320\u001b[0m │ gru2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ the_labels          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_length        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ label_length        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ctc (\u001b[38;5;33mLambda\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dense_output[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ the_labels[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                     │                   │            │ input_length[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ label_length[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │ image_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │ max_pooling2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">221,952</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> │ gru1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,320</span> │ gru2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ the_labels          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_length        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ label_length        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ctc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ the_labels[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                     │                   │            │ input_length[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ label_length[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m311,568\u001b[0m (1.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">311,568</span> (1.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m311,568\u001b[0m (1.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">311,568</span> (1.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m,   │        \u001b[38;5;34m160\u001b[0m │ image_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m,   │      \u001b[38;5;34m4,640\u001b[0m │ max_pooling2d_8[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_9[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m221,952\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m74,496\u001b[0m │ gru1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m10,320\u001b[0m │ gru2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ the_labels          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_length        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ label_length        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ctc (\u001b[38;5;33mLambda\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dense_output[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ the_labels[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                     │                   │            │ input_length[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ label_length[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │ image_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │ max_pooling2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">221,952</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> │ gru1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,320</span> │ gru2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ the_labels          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_length        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ label_length        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ctc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ the_labels[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                     │                   │            │ input_length[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ label_length[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m311,568\u001b[0m (1.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">311,568</span> (1.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m311,568\u001b[0m (1.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">311,568</span> (1.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}